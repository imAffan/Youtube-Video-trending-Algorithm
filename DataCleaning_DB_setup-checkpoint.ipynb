{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from config import dbuser, dbpassword, dbhost, dbport, dbname\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING A DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'video_id', 'title', 'publishedAt', 'channelTitle',\n",
       "       'categoryId', 'trending_date', 'views', 'likes', 'dislikes', 'comments',\n",
       "       'thumbnail_link'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================== #\n",
    "# # # CREATING A HEROKU DATASET\n",
    "# =============================================================== #\n",
    "# Heroku only takes data with <10k rows so I created a heroku dataset (incase we ever want to host on heroku).\n",
    "\n",
    "def import_func(country_code):\n",
    "    \n",
    "    # Creating Path\n",
    "    path = os.path.join('data','newData',f'{country_code}_youtube_trending_data.csv')\n",
    "    \n",
    "    # Storing dataframe to df\n",
    "    dfh=pd.read_csv(path)\n",
    "    \n",
    "    # Removing unwanted columns below\n",
    "    dfh=dfh[['video_id','title','publishedAt','channelTitle','categoryId','trending_date','view_count','likes','dislikes','comment_count','thumbnail_link']]\n",
    "    \n",
    "    # Renaming columns\n",
    "    dfh = dfh.rename(columns={'view_count': 'views', 'likes': 'likes', 'dislikes': 'dislikes', 'comment_count': 'comments'})\n",
    "    \n",
    "    # Changing object types to date types for two columns\n",
    "    dfh['publishedAt']=pd.to_datetime(dfh['publishedAt'])\n",
    "    dfh['trending_date']=pd.to_datetime(dfh['trending_date'])\n",
    "    \n",
    "    # Removing time stamp from date\n",
    "    dfh['publishedAt']=dfh['publishedAt'].dt.date \n",
    "    dfh['trending_date']=dfh['trending_date'].dt.date\n",
    "    \n",
    "    # For loop for each csv file\n",
    "    with open(f'data/newData/{country_code}_category_id.json', 'r') as read_file:\n",
    "        category_ids = json.load(read_file)\n",
    "\n",
    "        dfh=dfh.astype({'categoryId': 'str'})\n",
    "        \n",
    "    for index,row in dfh.iterrows():\n",
    "    \n",
    "        for entry in category_ids[\"items\"]:\n",
    "\n",
    "            if row[\"categoryId\"]==entry[\"id\"]:\n",
    "                dfh.at[index,\"categoryId\"]=entry[\"snippet\"][\"title\"]\n",
    "    \n",
    "    # Select 999 rows from each country in dataframe (so we end up with <10k rows ~1000 rows per country * 10 countries)\n",
    "    # dfh = dfh.nlargest(999, 'views')\n",
    "    \n",
    "    # Adding country Code as column\n",
    "    dfh['country']=f'{country_code}'\n",
    "    col_name='country'\n",
    "    \n",
    "    # Moving country code to first column\n",
    "    first_col = dfh.pop(col_name)\n",
    "    dfh.insert(0,col_name,first_col)\n",
    "    \n",
    "    return dfh\n",
    "\n",
    "# USA Dataframe\n",
    "dfh_us=import_func('US')\n",
    "\n",
    "# Brasil Dataframe\n",
    "dfh_br=import_func('BR')\n",
    "\n",
    "# Canada Dataframe\n",
    "dfh_ca=import_func('CA')\n",
    "\n",
    "# Mexico Dataframe\n",
    "dfh_mx=import_func('MX')\n",
    "\n",
    "# GB Dataframe\n",
    "dfh_gb=import_func('GB')\n",
    "\n",
    "# France Dataframe\n",
    "dfh_fr=import_func('FR')\n",
    "\n",
    "# Russia Dataframe\n",
    "dfh_ru=import_func('RU')\n",
    "\n",
    "# Japan Dataframe\n",
    "dfh_jp=import_func('JP')\n",
    "\n",
    "# Korea Dataframe\n",
    "dfh_kr=import_func('KR')\n",
    "\n",
    "# India Dataframe\n",
    "dfh_in=import_func('IN')\n",
    "\n",
    "\n",
    "# Creating a varible to add all dfs\n",
    "country_dfh=[dfh_us, dfh_br, dfh_ca, dfh_mx, dfh_gb, dfh_fr, dfh_ru ,dfh_jp, dfh_kr ,dfh_in]\n",
    "\n",
    "# Merge output into one table\n",
    "dfh_main = pd.concat(country_dfh)\n",
    "dfh_main\n",
    "\n",
    "# Fix the 29 vs Non profits issue\n",
    "dfh_main['categoryId'] = dfh_main['categoryId'].replace([\"29\"],\"Nonprofits & Activism\")\n",
    "\n",
    "# View output\n",
    "dfh_main.columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comments</th>\n",
       "      <th>thumbnail_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>3C66w5Z0ixs</td>\n",
       "      <td>I ASKED HER TO BE MY GIRLFRIEND...</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>Brawadis</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2020-08-12</td>\n",
       "      <td>1514614</td>\n",
       "      <td>156908</td>\n",
       "      <td>5855</td>\n",
       "      <td>35313</td>\n",
       "      <td>https://i.ytimg.com/vi/3C66w5Z0ixs/default.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>M9Pmf9AB4Mo</td>\n",
       "      <td>Apex Legends | Stories from the Outlands ‚Äì ‚ÄúTh...</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>Apex Legends</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>2020-08-12</td>\n",
       "      <td>2381688</td>\n",
       "      <td>146739</td>\n",
       "      <td>2794</td>\n",
       "      <td>16549</td>\n",
       "      <td>https://i.ytimg.com/vi/M9Pmf9AB4Mo/default.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>J78aPJ3VyNs</td>\n",
       "      <td>I left youtube for a month and THIS is what ha...</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>jacksepticeye</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2020-08-12</td>\n",
       "      <td>2038853</td>\n",
       "      <td>353787</td>\n",
       "      <td>2628</td>\n",
       "      <td>40221</td>\n",
       "      <td>https://i.ytimg.com/vi/J78aPJ3VyNs/default.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>kXLn3HkpjaA</td>\n",
       "      <td>XXL 2020 Freshman Class Revealed - Official An...</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>XXL</td>\n",
       "      <td>Music</td>\n",
       "      <td>2020-08-12</td>\n",
       "      <td>496771</td>\n",
       "      <td>23251</td>\n",
       "      <td>1856</td>\n",
       "      <td>7647</td>\n",
       "      <td>https://i.ytimg.com/vi/kXLn3HkpjaA/default.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>VIUo6yapDbc</td>\n",
       "      <td>Ultimate DIY Home Movie Theater for The LaBran...</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>Mr. Kate</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "      <td>2020-08-12</td>\n",
       "      <td>1123889</td>\n",
       "      <td>45802</td>\n",
       "      <td>964</td>\n",
       "      <td>2196</td>\n",
       "      <td>https://i.ytimg.com/vi/VIUo6yapDbc/default.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44135</td>\n",
       "      <td>IN</td>\n",
       "      <td>owXrUjCzR3s</td>\n",
       "      <td>Dearu Brotheru | 1 Crore Views Special Mashup ...</td>\n",
       "      <td>2021-04-03</td>\n",
       "      <td>Sema Bruh</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>475622</td>\n",
       "      <td>42231</td>\n",
       "      <td>326</td>\n",
       "      <td>723</td>\n",
       "      <td>https://i.ytimg.com/vi/owXrUjCzR3s/default.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44136</td>\n",
       "      <td>IN</td>\n",
       "      <td>cqn3OqwU7KA</td>\n",
       "      <td>Bicycle Bhais | Web Series | Episode 3 | But W...</td>\n",
       "      <td>2021-04-03</td>\n",
       "      <td>Popcorn Stories</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>177265</td>\n",
       "      <td>10847</td>\n",
       "      <td>338</td>\n",
       "      <td>273</td>\n",
       "      <td>https://i.ytimg.com/vi/cqn3OqwU7KA/default.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44137</td>\n",
       "      <td>IN</td>\n",
       "      <td>niDk_Ydotk8</td>\n",
       "      <td>‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•á ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§Æ‡•Ä‡§∞ ‡§á‡§Ç‡§∏‡§æ‡§® ‡§ï‡§æ ‡§™‡•ç‡§∞‡•ã‡§ú‡•á‡§ï‡•ç‡§ü - Jeff ...</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>FactTechz</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>1442530</td>\n",
       "      <td>159830</td>\n",
       "      <td>1946</td>\n",
       "      <td>5018</td>\n",
       "      <td>https://i.ytimg.com/vi/niDk_Ydotk8/default.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44138</td>\n",
       "      <td>IN</td>\n",
       "      <td>5PnhUOl-K-A</td>\n",
       "      <td>KHUSHI MEETS MOM üò¢ | Vivek Choudhary | Khushi ...</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>Mr &amp; Mrs Choudhary</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>1242032</td>\n",
       "      <td>102200</td>\n",
       "      <td>1434</td>\n",
       "      <td>7439</td>\n",
       "      <td>https://i.ytimg.com/vi/5PnhUOl-K-A/default.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44139</td>\n",
       "      <td>IN</td>\n",
       "      <td>wF6tm_mznvA</td>\n",
       "      <td>Extra Jabardasth | 2nd April 2021 | Full Episo...</td>\n",
       "      <td>2021-04-02</td>\n",
       "      <td>ETV Jabardasth</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>2694290</td>\n",
       "      <td>27406</td>\n",
       "      <td>2572</td>\n",
       "      <td>1074</td>\n",
       "      <td>https://i.ytimg.com/vi/wF6tm_mznvA/default.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463662 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country     video_id                                              title  \\\n",
       "0          US  3C66w5Z0ixs                 I ASKED HER TO BE MY GIRLFRIEND...   \n",
       "1          US  M9Pmf9AB4Mo  Apex Legends | Stories from the Outlands ‚Äì ‚ÄúTh...   \n",
       "2          US  J78aPJ3VyNs  I left youtube for a month and THIS is what ha...   \n",
       "3          US  kXLn3HkpjaA  XXL 2020 Freshman Class Revealed - Official An...   \n",
       "4          US  VIUo6yapDbc  Ultimate DIY Home Movie Theater for The LaBran...   \n",
       "...       ...          ...                                                ...   \n",
       "44135      IN  owXrUjCzR3s  Dearu Brotheru | 1 Crore Views Special Mashup ...   \n",
       "44136      IN  cqn3OqwU7KA  Bicycle Bhais | Web Series | Episode 3 | But W...   \n",
       "44137      IN  niDk_Ydotk8  ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•á ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§Æ‡•Ä‡§∞ ‡§á‡§Ç‡§∏‡§æ‡§® ‡§ï‡§æ ‡§™‡•ç‡§∞‡•ã‡§ú‡•á‡§ï‡•ç‡§ü - Jeff ...   \n",
       "44138      IN  5PnhUOl-K-A  KHUSHI MEETS MOM üò¢ | Vivek Choudhary | Khushi ...   \n",
       "44139      IN  wF6tm_mznvA  Extra Jabardasth | 2nd April 2021 | Full Episo...   \n",
       "\n",
       "      publishedAt        channelTitle            categoryId trending_date  \\\n",
       "0      2020-08-11            Brawadis        People & Blogs    2020-08-12   \n",
       "1      2020-08-11        Apex Legends                Gaming    2020-08-12   \n",
       "2      2020-08-11       jacksepticeye         Entertainment    2020-08-12   \n",
       "3      2020-08-11                 XXL                 Music    2020-08-12   \n",
       "4      2020-08-11            Mr. Kate         Howto & Style    2020-08-12   \n",
       "...           ...                 ...                   ...           ...   \n",
       "44135  2021-04-03           Sema Bruh                Comedy    2021-04-07   \n",
       "44136  2021-04-03     Popcorn Stories                Comedy    2021-04-07   \n",
       "44137  2021-04-05           FactTechz  Science & Technology    2021-04-07   \n",
       "44138  2021-04-05  Mr & Mrs Choudhary        People & Blogs    2021-04-07   \n",
       "44139  2021-04-02      ETV Jabardasth                Comedy    2021-04-07   \n",
       "\n",
       "         views   likes  dislikes  comments  \\\n",
       "0      1514614  156908      5855     35313   \n",
       "1      2381688  146739      2794     16549   \n",
       "2      2038853  353787      2628     40221   \n",
       "3       496771   23251      1856      7647   \n",
       "4      1123889   45802       964      2196   \n",
       "...        ...     ...       ...       ...   \n",
       "44135   475622   42231       326       723   \n",
       "44136   177265   10847       338       273   \n",
       "44137  1442530  159830      1946      5018   \n",
       "44138  1242032  102200      1434      7439   \n",
       "44139  2694290   27406      2572      1074   \n",
       "\n",
       "                                       thumbnail_link  \n",
       "0      https://i.ytimg.com/vi/3C66w5Z0ixs/default.jpg  \n",
       "1      https://i.ytimg.com/vi/M9Pmf9AB4Mo/default.jpg  \n",
       "2      https://i.ytimg.com/vi/J78aPJ3VyNs/default.jpg  \n",
       "3      https://i.ytimg.com/vi/kXLn3HkpjaA/default.jpg  \n",
       "4      https://i.ytimg.com/vi/VIUo6yapDbc/default.jpg  \n",
       "...                                               ...  \n",
       "44135  https://i.ytimg.com/vi/owXrUjCzR3s/default.jpg  \n",
       "44136  https://i.ytimg.com/vi/cqn3OqwU7KA/default.jpg  \n",
       "44137  https://i.ytimg.com/vi/niDk_Ydotk8/default.jpg  \n",
       "44138  https://i.ytimg.com/vi/5PnhUOl-K-A/default.jpg  \n",
       "44139  https://i.ytimg.com/vi/wF6tm_mznvA/default.jpg  \n",
       "\n",
       "[463662 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View output\n",
    "dfh_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONNECTING AND LOADING DATA INTO THE DATABASE (POSTGRES & MSSQL DBs) FOR HEROKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================== #\n",
    "# # UPLOAD DATASET TO DATABASE (POSTGRESS SQL DB)\n",
    "# =============================================================== #\n",
    "# You first have to go create the db and then use the same name as the db you have created\n",
    "# (youtube_table_v1 < 10,000    youtube_table_v2 > 10,000) in postgres\n",
    "\n",
    "# =============================================================== #\n",
    "# # 1 Connect to Database (with Local db and all)\n",
    "# =============================================================== #\n",
    "# pg_user = 'postgres'\n",
    "# pg_password=password\n",
    "# db_name = 'youtube_database'\n",
    "# connection_string = f'{pg_user}:{password}@localhost:5432/{db_name}'\n",
    "# engine=create_engine(f'postgresql://{connection_string}')\n",
    "\n",
    "# =============================================================== #\n",
    "# 2 Connect to Database (Alternative with AWS db and all)\n",
    "# =============================================================== #\n",
    "dbuser = 'postgres'\n",
    "dbpassword = 'Sm6Jc5bqbiNQdsVAo7eN'\n",
    "dbhost = 'localhost'\n",
    "dbport = '5432'\n",
    "dbname= 'YTP_database'\n",
    "connection_string2 = f'{dbuser}:{dbpassword}@database-1.cvmfiiilpm7y.us-east-1.rds.amazonaws.com:{dbport}/{dbname}'\n",
    "engine=create_engine(f'postgresql://{connection_string2}')\n",
    "\n",
    "# =============================================================== #\n",
    "# 3 Upload to postgres\n",
    "# =============================================================== #\n",
    "dfh_main.to_sql(name='youtube_table_v2',con=engine,if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================== #\n",
    "# # UPLOAD DATASET TO DATABASE (SQL SERVER DB)\n",
    "# =============================================================== #\n",
    "# =============================================================== #\n",
    "# IMPORTING DEPENDENCIES\n",
    "# =============================================================== #\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "\n",
    "# =============================================================== #\n",
    "# Set up variables\n",
    "# =============================================================== #\n",
    "msql_serverName = 'WORKHORSE_PC\\SQLEXPRESS'\n",
    "msql_dbName = 'YTP_Parser'\n",
    "\n",
    "# =============================================================== #\n",
    "# Set up connection string (This connection string is for SQL \n",
    "# server which are set up without username & pw)\n",
    "# =============================================================== #\n",
    "conn_str = (\n",
    "    r'Driver=ODBC Driver 17 for SQL Server;'\n",
    "    rf'Server={msql_serverName};'\n",
    "    rf'Database={msql_dbName};'\n",
    "    r'Trusted_Connection=yes;'\n",
    ")\n",
    "quoted_conn_str = urllib.parse.quote_plus(conn_str)\n",
    "engine = create_engine(f'mssql+pyodbc:///?odbc_connect={quoted_conn_str}')\n",
    "\n",
    "# =============================================================== #\n",
    "# Connect to DB and delete (or create) a table\n",
    "# =============================================================== #\n",
    "# q = \"\"\"DROP TABLE Table2BDeleted\"\"\"\n",
    "# cnxn.execute(q)   \n",
    "\n",
    "# q = \"\"\" \n",
    "# CREATE TABLE youtube_table_v2 (\n",
    "# country Varchar (128) NOT NULL,\n",
    "# video_id Varchar (128) NOT NULL,\n",
    "# title Varchar (128) NOT NULL,\n",
    "# publishedAt date NOT NULL,\n",
    "# channelTitle Varchar (128) NOT NULL,\n",
    "# categoryId Varchar (128) NOT NULL,\n",
    "# trending_date date NOT NULL,\n",
    "# views Integer NOT NULL,\n",
    "# likes Integer NOT NULL,\n",
    "# dislikes Integer NOT NULL,\n",
    "# comments Integer NOT NULL,\n",
    "# thumbnail_link Varchar (128) NOT NULL,\n",
    "# )\n",
    "# \"\"\"\n",
    "# cnxn.execute(q)  \n",
    "\n",
    "# =============================================================== #\n",
    "# Connect to DB and upload df to table\n",
    "# =============================================================== #\n",
    "cnxn = engine.connect()\n",
    "dfh_main.to_sql(name = 'youtube_table_v2', con = cnxn, if_exists = 'append',index = False)\n",
    "cnxn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
